
\documentclass[a4paper,14pt]{extarticle}

\usepackage{cmap}

\usepackage[T2A]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[russian]{babel}

\usepackage[a4paper,margin=1.5cm,footskip=1cm,left=2cm,right=1.5cm,top=1.5cm
  ,bottom=2.0cm]{geometry}
\usepackage{textcase}
\usepackage{csquotes}
\usepackage{enumitem}

\usepackage[labelsep=period,justification=centering]{caption}

\usepackage{graphicx}
\graphicspath{ {figure/} }

\usepackage{amsmath}
\usepackage{pgfplots}

\usepackage{float}

\usepackage{indentfirst}

\usepackage{textgreek}

\usepackage{pythontex}

\usepackage{comment}

% 
\setlist[description]{leftmargin=\parindent,labelindent=\parindent}

\renewcommand{\baselinestretch}{1.5}

\usepackage[titletoc,title]{appendix}

\DeclareMathOperator{\Sp}{Sp}

\newcommand{\pred}[0]{t_{k+1}|t_k}
\newcommand{\est}[0]{t_k|t_k}
\newcommand{\fut}[0]{t_{k+1}}
\newcommand{\estfut}[0]{t_{k+1}|t_{k+1}}

\renewcommand{\vec}[1]{#1}

\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pdpk}[1]{\pd{#1}{\theta_i}}

\newcommand{\inv}[1]{#1^{-1}}

\newcommand{\eps}{\varepsilon}

\begin{document}

\setcounter{secnumdepth}{0}

\begin{titlepage}

  \begin{center}
    Новосибирский государственный технический университет
    
    Факультет прикладной математики и информатики
    
    Кафедра теоретической и прикладной информатики
    
    \vspace{250pt}
    
    \textbf{\Large{Лабораторная работа № 2}}
    \medbreak
		<<Активная параметрическая идентификация моделей линейных дискретных
		динамических стохастических систем>> \medbreak
    по дисциплине \\
    \medbreak
    <<Математические методы планирования эксперимента>>
    \vspace{100pt}
  \end{center}

  \begin{flushleft}
    \begin{tabbing}
      Группа:\qquad\qquad \= ПММ-61\\
      Студент:            \> Горбунов К. К.\\
      Преподаватель:      \> Чубич В. М.\\
    \end{tabbing}
  \end{flushleft}

  \begin{center}
    \vspace{\fill}
    Новосибирск, 2017 г.
  \end{center}

\end{titlepage}

\newpage

\section{Цель работы}

Реализовать процедуру активной параметрической идентификации, экспериментально
подтвердить её эффективность.

\section{Порядок выполнения лабораторной работы}

\begin{enumerate}
\item Изучить соответствующий теоретический материал.

\item Последовательно выполнить все задания к лабораторной работе.

\item Проверить правильность реализации алгоритмов и работоспособность
  программ.

\end{enumerate}

\section{Задание к лабораторной работе}

\begin{enumerate}

\item Связать разработанные ранее программные модули оценивания параметров
	и планирования оптимальных входных сигналов.

\item Для некоторой модели стохастической линейной дискретной системы 
	получить начальные оценки параметров по некоторому произвольному начальному
		плану эксперимента.

\item При полученных начальных оценках параметров синтезировать оптимальный
	непрерывный план идентификационного эксперимента, округлить полученный
		непрерывный план до дискретного.

\item Провести идентификационный эксперимент согласно полученному дискретному
	оптимальному плану.

\item Сравнить точность оценивания параметров по исходному и оптимальному
	планам.

\end{enumerate}

\section{Теоретический материал}

\subsection{Основы активной параметрической идентификации}

Предоположим, что экспериментатор может произвести $\nu$ повторных запусков
системы, причем сигнал $\alpha_1$ он подает на вход системы $k_1$ раз, сигнал
$\alpha_2$ --- $k_2$ раза и так далее, наконец, сигнал $\alpha_q$ --- $k_q$
раз. В этом случае дискретный (точный) нормированный план эксперимента
$\xi_{\nu}$ представляет собой совокупность точек $\alpha_1, \alpha_2, \ldots,
\alpha_q$, называемых спектром плана, и соответствующих им долей повторных
запусков:
\begin{equation*}
	\xi_{\nu} = \left\{
		\begin{array}{cc} 
			\alpha_1, \alpha_2, \ldots, \alpha_q \\
			\frac{k_1}{\nu}, \frac{k_2}{\nu}, \ldots, \frac{k_q}{\nu}
		\end{array} \right\},\ \alpha_i \in \Omega_{\alpha},\ i = 1, 2, \ldots, q.
\end{equation*}

Каждая точка $\alpha_i$ спектра плана представляет собой последовательность
импульсов, <<развернутую во времени>>, т.е.
\[
	\alpha_i^T = U_i^T = \left\{ [u^i(t_0)]^T, [u^i(t_1)]^T, \ldots,
	[u^i(t_{N-1})]^T \right\},\ i = 1, 2, \ldots, q.
\]
Множество планирования $\Omega_{\alpha}$ определяется ограничениями на условия
проведения эксперимента.

Под непрерывным планом $\xi$ понимается совокупность величин
\begin{equation*}
	\xi = \left\{
		\begin{array}{cc} 
			\alpha_1, \alpha_2, \ldots, \alpha_q \\
			p_1, p_2, \ldots, p_q	
		\end{array} \right\},\ 
	p_i \ge 0,\ 
	\sum\limits_{i=1}^q p_i = 1,\ \alpha_i \in \Omega_{\alpha},\ 
	i = 1, 2, \ldots, q.
\end{equation*}

В отличие от дискретного нормированного плана в непрерывном нормированном плане
снимается условие рациональности весов $p_i$.

Из непрерывного плана можно получить дискретный путем его округления.

Если $L(Y_1^N; \Theta)$ --- плотность совместного распределения вероятностей по
совокупности измерений $Y_1^N = \{ y(t_1), y(t_2), \ldots, y(t_N) \}$ при
фиксированном значении вектора параметров $\Theta$, то информационная матрица
Фишера одноточечного плана определяется выражениями \cite{mono}:
\begin{equation*}
	M(\alpha) = 
	\begin{Vmatrix} 
		\underset{Y}{E}
		\left[ 
			\frac{\partial \ln L(Y_1^N; \Theta)}{\partial \theta_i}
			\frac{\partial \ln L(Y_1^N; \Theta)}{\partial \theta_j}
		\right]
	\end{Vmatrix} =
	\begin{Vmatrix} 
		\underset{Y}{E}
		\left[ 
			-\frac{\partial^2 \ln L(Y_1^N; \Theta)}
			{\partial \theta_i \partial \theta_j}
		\right]
	\end{Vmatrix}
\end{equation*}

Тогда нормированная информационная матрица $M(\xi)$ плана $\xi$ определяется
соотношением:
\[
	M(\xi) = \sum\limits_{i=1}^q p_i M(\alpha_i),
\]
где $M(\alpha_i)$ --- информационные матрицы точек спектра плана.

Задача построения оптимального плана эксперимента $\xi^*$ сводится к задаче:
\[
	\xi^* = \arg \min\limits_{\xi \in \Omega_{\xi}} X[M(\xi)],
\]
где $\Omega_{\xi}$ --- область планирования, $X$ --- критерий оптимальности.
Данную задачу можно решать путем прямой и двойственной процедур.

Если через $Y_{i,j}$ обозначить $j$-ю реализацию выходного сигнала ($j = 1, 2,
\ldots, k_i$), соответствующему $i$-му входному сигналу $U_i$ ($i = 1, 2,
\ldots, q$), то в результате проведения по плану $\xi_{\nu}$ идентификационных
экспериментов будет сформировано множество
\[
	\Xi = \left\{ 
		(U_i, Y_{i,j}),\ j = 1, 2, \ldots, k_i,\ i = 1, 2, \ldots, q
	\right\}
\]

Уточним структуру $Y_{i,j}$:
\[
	Y_{i,j}	= \left\{ 
		[y^{i,j}(t_1)]^T, [y^{i,j}(t_2)]^T, \ldots, [y^{i,j}(t_N)]^T \right\},\
		j = 1, 2, \ldots, k_i,\ i = 1, 2, \ldots, q
\]

Задача оценивания параметров $\theta$ сводится к задаче:
\[
	\hat{\theta} = \arg \min\limits_{\theta \in \Omega_{\theta}} \chi(\Xi,
	\theta),
\]
где $\chi$ --- критерий идентификации.

\subsubsection{Алгоритм процедуры активной параметрической идентификации:}

\begin{enumerate}
	\item Взять произвольный (можно случайный) план $\xi_0$,
		тогда в результате проведения идентификационных экспериментов по данному
		плану будет сформировано множество $\Xi_0$;
	\item Получить начальные оценки $\hat{\theta}_0$ параметров модели
		по плану $\xi_0$, решая задачу:
\[
	\hat{\theta}_0 = \arg\min\limits_{\theta \in \Omega_{\theta}}
		\chi(\Xi_0, \theta);
\]
	\item Провести процедуру (прямую или двойственную) оптимального планирования
		входных сигналов --- получить план $\xi^{*}$, решая следующую задачу,
		используя найденные найденные ранее оценки $\hat{\theta}_0$:
\[
	\xi^{*} = \arg\min\limits_{\xi \in \Omega_{\xi}} X[M(\xi), \hat{\theta}_0].
\]
	Множество, сформированное в результате проведения идентификационных
		экспериментов по плану $\xi^{*}$ обозначим как $\Xi^{*}$.
	\item Получить конечные оценки $\hat{\theta}$ параметров модели по ранее
		синтезированному оптимальному плану $\xi^{*}$:
\[
	\hat{\theta} = \arg\min\limits_{\theta \in \Omega_{\theta}} \chi(\Xi^{*},
		\theta);
\]
и закончить процесс.

\end{enumerate}

\newpage
\subsection{Описание модельной структуры}

Модель стохастической динамической линейной дискретной системы в пространстве
состояний в виде \cite{mono}:
\begin{equation}
  \label{eq:initmod}
  \left\{ 
    \begin{array}{lll}
      \vec{x}(t_{k+1}) &= F \vec{x}(t_k) + C \vec{u}(t_k) + G \vec{w}(t_k),&\\
      \vec{y}(t_{k+1}) &= H \vec{x}(t_{k+1}) + \vec{v}(t_{k+1}), 
      & k = 0,\ldots, N-1
    \end{array} 
  \right. 
\end{equation}

Здесь:
\begin{description}
  \item [$\vec{x}(t_k)$] -- $n$-вектор состояния;
  \item [$F$] -- матрица перехода состояния;
  \item [$\vec{u}(t_k)$] -- $r$-вектор управления (входного воздействия);
  \item [$C$] -- матрица управления;
  \item [$\vec{w}(t_k)$] -- $p$-вектор возмущений;
  \item [$G$] -- матрица влияния возмущений;
  \item [$H$] -- матрица наблюдения;
  \item [$\vec{v}(t_{k+1})$] -- $m$-вектор шума измерений;
  \item [$\vec{y}(t_{k+1})$] -- $m$-вектор наблюдений (измерений) отклика;
\end{description}

$F, C, G, H$ --- матрицы соответствующих размеров.

\bigskip
Априорные предположения:
\begin{itemize}
\item $F$ устойчива;
\item пары $(F, C)$ и $(F, G)$ управляемы;
\item пара $(F, H)$ --- наблюдаема;
\item $\vec{w}(t_k)$ и $\vec{v}(t_{k+1})$ --- случайные векторы, образующие
стационарные белые гауссовские последовательности, причем:
\[
E[\vec{w}(t_k)] = 0,\ E[\vec{w}(t_k)\vec{w}^{T}(t_l)] = Q \delta_{k,l}\ ;
\]
\[
E[\vec{v}(t_{k+0}) = 0,\ E[\vec{v}(t_{k+1})\vec{v}^{T}(t_{l+1})] = R
\delta_{k,l}\;
\]
\[
E[\vec{v}(t_k)\vec{w}^{T}(t_k)] = 0,
\]
для любых $k, l = 0, 1, \ldots, N-1$ ($\delta_{k,l}$ --- символ Кронекера);

\item начальное состояние $\vec{x}(0)$ имеет нормальное распределение с
параметрами $\overline{\vec{x}}(0)$ и $P(0)$ и не коррелирует с $\vec{w(t_k)}$
и $\vec{v_{k+1}}$ при любых значениях $k$.

Будем считать, что подлежащие оцениванию параметры $\theta = (\theta_1,
\theta_2, \ldots, \theta_s)$ могут входить в элементы матриц $F, C, G, H, Q, R,
P(0)$ и в вектор $\overline{\vec{x}}(0)$ в различных комбинациях.

\end{itemize}

\subsection{Критерий идентификации}

В качестве критерия идентификации используется логарифмическая функция
правдоподобия. Для одноточечного плана эксперимента она имеет вид \cite{mono}:
\begin{equation*}
\begin{split}
	\chi(\theta, U_i, Y_{i,j}) = -\ln{L(\theta)} =
	\frac{Nm}{2}\ ln{2\pi} + \frac{1}{2}
	\sum\limits_{k=0}^{N-1} \left[ [\eps^{i,j}(t_{k+1})]^T 
	B^{-1}(t_{k+1}) \eps^{i,j}(t_{k+1}) \right]
  + \\ + \frac{1}{2} \sum\limits_{k=0}^{N-1} \ln \det B^{-1}(t_{k+1}).
\end{split}
\end{equation*}

Критерий идентификации для многоточечного плана имеет вид:

\begin{equation*}
	\chi(\Xi, \theta) =
		\sum\limits_{i=1}^{q} \sum\limits_{j=1}^{k_i} \chi(\theta, U_i, Y_{i,j})
\end{equation*}

\subsection{Градиент критерия идентификации}

Выражение для градиента критерия для одноточечного плана имеет вид \cite{mono}:
\begin{equation*}
\begin{split}
  \frac{\partial \chi(\theta)}{\partial \theta_l} = \sum\limits_{k=0}^{N-1}
  \left[ \frac{\partial \eps(t_{k+1})}{\partial \theta_l} \right]^T
  B^{-1}(t_{k+1}) \left[ \eps(t_{k+1}) \right] - \\
  - \frac{1}{2}
  \sum\limits_{k=0}^{N-1} \left[ \eps(t_{k+1}) \right]^T B^{-1}(t_{k+1})
  \frac{\partial B(t_{k+1})}{\partial \theta_i} B^{-1}(t_{k+1}) \eps(t_{k+1}) +
  \\ + 
  \frac{1}{2} \sum\limits_{k=0}^{N-1} \Sp \left[ B^{-1}(t_{k+1})
  \frac{\partial B(t_{k+1})}{\partial \theta_l} \right],\ l = 1, 2, \ldots, s.
\end{split}
\end{equation*}

Выражение градиента критерия для многоточечного плана можно легко получить по
правилу дифференцирования суммы.

% imports
\begin{pythontexcustomcode}{py}
import numpy as np
import dill as pkl
from model.model import Model
import pylatex
\end{pythontexcustomcode}

\section{Пример активной идентификации}

% TODO: introduce counter
% TODO: print numpy arrays instead of matrices
\[
  \begin{pmatrix} x_1(\fut) \\ x_2(\fut) \end{pmatrix} =
  \begin{pmatrix} \theta_1 & 1 \\ 0 & 0.5 \end{pmatrix}
  \begin{pmatrix} x_1(t_k) \\ x_2(t_k) \end{pmatrix}
  + 
	\begin{pmatrix} \theta_2 \\ 1 \end{pmatrix}
	u(t_k) 
  + \begin{pmatrix} w_1(t_k) \\ w_2(t_k) \end{pmatrix}
\]
\[
  y(\fut) =
	\begin{pmatrix} 1 & 0 \end{pmatrix}
	\begin{pmatrix} x_1(\fut) \\ x_2(\fut) \end{pmatrix} +
  \begin{pmatrix} v_1(\fut) \\ v_2(\fut) \end{pmatrix}
\]
\[
  \overline{x}(0) = \begin{pmatrix} 0 \\ 0 \end{pmatrix},\
  P(0) = \begin{pmatrix} 0.1 & 0 \\ 0 & 0.1 \end{pmatrix},\
  Q = \begin{pmatrix} 0.1 & 0 \\ 0 & 0.1 \end{pmatrix},\
  R = 0.1 
\]

Истинные значения параметров
$\theta_{true} = \begin{pmatrix} 0.5 & 0.5 \end{pmatrix}$ \\

\newpage
\subsubsection{Оценивание параметров по произвольному начальному плану}

Спектр непрерывного начального плана:

\begin{pycode}[][fontsize=\small]
filename = './data/plan0.pkl'
with open(filename, 'rb') as f:
    plan0 = pkl.load(f)

def print_plan_tex(plan0):
	print('$')
	print('U = \\left\{')

	for i in range(plan0[0].shape[0]-1):
		x = plan0[0][i]
		xx = pylatex.Matrix(np.round(x.T, 2), mtype='b').dumps()
		print(xx)
		print(',\ ')

	xx = pylatex.Matrix(np.round(plan0[0][-1].T), mtype='b').dumps()
	print(xx)
			
	print('\\right\}')
	print('$')

print_plan_tex(plan0)
\end{pycode}
\newline

Веса непрерывного начального плана:
\begin{pycode}
p = np.array(plan0[1], ndmin=2)
p = pylatex.Matrix(p, mtype='b').dumps()
print('$ p = ')
print(p)
print('$')
\end{pycode}

Длина точки плана $N = 20$.

Область планирования: $u(t_k) \in [ -1,\ 1 ],\ k = 0, 1, \ldots, N$.

Область оценивания: $ 0.25 \le \theta_i \le 0.75,\ i = 1, 2 $.

Общее число запусков $\nu = 10$. \\

Веса соответствующего дискретного начального плана:
\begin{pycode}
def round_w(p, v):
	import operator
	p = np.array(p)
	q = len(p)
	sigmaI = np.ceil((v - q) * p)  # 1
	sigmaII = np.floor(v * p)
	vI = v - np.sum(sigmaI)  # 2
	vII = v - np.sum(sigmaII)
	if vI < vII:
			sigma = sigmaI
			v1 = int(vI)
	else:
			sigma = sigmaII
			v1 = int(vII)

	s = np.zeros(q)

	vps = v * p - sigma
	vps_id = [i for i in range(len(vps))]
	vps_t = [(val, key) for val, key in zip(vps, vps_id)]

	vps_t = sorted(vps_t, key=operator.itemgetter(0))
	sorted_id = [elem[1] for elem in vps_t]

	for j in range(q):
			if vps_id[j] in sorted_id[:v1]:
					s[j] = 1
			else:
					s[j] = 0

	p = (sigma + s) / v
	return p

p = round_w(plan0[1], 10)
p = np.array(p, ndmin=2)
p = pylatex.Matrix(p, mtype='b').dumps()
print('$ p = ')
print(p)
print('$')
\end{pycode}

Полученные оценки параметров:
$\hat{\theta} = \begin{bmatrix} 0.342 & 0.559 \end{bmatrix}$.

\newcommand{\rtol}[2]{\frac{||\hat{#1}#2 -
{\hat{#1}#2_{true}}||}{||\hat{#1}#2_{true}||}}

Относительная погрешность в пространстве параметров:
\[
	\delta_{\theta} = \rtol{\theta}{} = 23.9\%.
\]

Средняя относительная погрешность в пространстве откликов:
\[
	\overline{\delta}_Y = \frac{1}{\nu}
		\sum\limits_{i=1}^{q}\sum\limits_{j=1}^{k_i} \rtol{Y}{^{i,j}} = 11.8 \%.
\]

\subsubsection{Синтез оптимального плана и оценивание параметров по плану}

По проведению двойственной процедуры планирования входных сигналов был получен
некоторый оптимальный план. В результате проведения идентификационных экспериментов по
данному плану были получены оценки параметров.

\newpage
Спектр оптимального плана:

\begin{pycode}
filename = './data/plan1.pkl'
with open(filename, 'rb') as f:
    plan1 = pkl.load(f)

print_plan_tex(plan1)
\end{pycode}

То есть в плане одна точка, соответственно, все запуски $\nu$ будут приходиться
на неё.

Полученные оценки параметров:
$\hat{\theta} = \begin{bmatrix} 0.46 & 0.47 \end{bmatrix}$.

Относительная погрешность в пространстве параметров:
\[
	\delta_{\theta} = \rtol{\theta}{} = 6.7\%.
\]

Средняя относительная погрешность в пространстве откликов:
\[
	\overline{\delta}_Y = \frac{1}{\nu}
		\sum\limits_{i=1}^{q}\sum\limits_{j=1}^{k_i} \rtol{Y}{^{i,j}} = 2.6 \%.
\]

\section{Выводы}

По результатам эксперимента видно уменьшение погрешности оценок при оценивании
по оптимальному плану. Таким образом подтверждается эффективность процедуры
активной параметрической идентификации.

\begin{thebibliography}{9}

\begin{sloppypar}

\bibitem{mono} Активная параметрическая идентификация стохастических линейных
  систем: монография / В.И. Денисов, В.М. Чубич, О.С. Черникова, Д.И. Бобылева.
    --- Новосибирск : Изд-во НГТУ, 2009. --- 192 с.
    (Серия <<Монографии НГТУ>>).

\end{sloppypar}

\end{thebibliography}

\renewcommand{\baselinestretch}{1}

\end{document}

# vim: ts=2 sw=2
