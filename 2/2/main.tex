
\documentclass[a4paper,14pt]{extarticle}

\usepackage{cmap}

\usepackage[T2A]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[russian]{babel}

\usepackage[a4paper,margin=1.5cm,footskip=1cm,left=2cm,right=1.5cm,top=1.5cm
  ,bottom=2.0cm]{geometry}
\usepackage{textcase}
\usepackage{csquotes}
\usepackage{enumitem}

\usepackage[labelsep=period,justification=centering]{caption}

\usepackage{graphicx}
\graphicspath{ {figure/} }

\usepackage{amsmath}
\usepackage{pgfplots}

\usepackage{float}

\usepackage{indentfirst}

\usepackage{textgreek}

\usepackage{pythontex}

\usepackage{comment}

% 
\setlist[description]{leftmargin=\parindent,labelindent=\parindent}

\renewcommand{\baselinestretch}{1.5}

\usepackage[titletoc,title]{appendix}

\DeclareMathOperator{\Sp}{Sp}

\newcommand{\pred}[0]{t_{k+1}|t_k}
\newcommand{\est}[0]{t_k|t_k}
\newcommand{\fut}[0]{t_{k+1}}
\newcommand{\estfut}[0]{t_{k+1}|t_{k+1}}

\renewcommand{\vec}[1]{#1}

\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pdpk}[1]{\pd{#1}{\theta_i}}

\newcommand{\inv}[1]{#1^{-1}}

\newcommand{\eps}{\varepsilon}

\begin{document}

\setcounter{secnumdepth}{0}

\begin{titlepage}

  \begin{center}
    Новосибирский государственный технический университет
    
    Факультет прикладной математики и информатики
    
    Кафедра теоретической и прикладной информатики
    
    \vspace{250pt}
    
    \textbf{\Large{Лабораторная работа № 2}}
    \medbreak
		<<Активная параметрическая идентификация моделей линейных дискретных
		динамических стохастических систем>> \medbreak
    по дисциплине \\
    \medbreak
    <<Математические методы планирования эксперимента>>
    \vspace{100pt}
  \end{center}

  \begin{flushleft}
    \begin{tabbing}
      Группа:\qquad\qquad \= ПММ-61\\
      Студент:            \> Горбунов К. К.\\
      Преподаватель:      \> Чубич В. М.\\
    \end{tabbing}
  \end{flushleft}

  \begin{center}
    \vspace{\fill}
    Новосибирск, 2017 г.
  \end{center}

\end{titlepage}

\newpage

\section{Цель работы}

Реализовать процедуру активной параметрической идентификации, экспериментально
подтвердить её эффективность.

\section{Порядок выполнения лабораторной работы}

\begin{enumerate}
\item Изучить соответствующий теоретический материал.

\item Последовательно выполнить все задания к лабораторной работе.

\item Проверить правильность реализации алгоритмов и работоспособность
  программ.

\end{enumerate}

\section{Задание к лабораторной работе}

\begin{enumerate}

\item Связать разработанные ранее программные модули оценивания параметров
	и планирования оптимальных входных сигналов.

\item Для некоторой модели стохастической линейной дискретной системы 
	получить начальные оценки параметров по некоторому произвольному начальному
		плану эксперимента.

\item При полученных начальных оценках параметров синтезировать оптимальный
	непрерывный план идентификационного эксперимента, округлить полученный
		непрерывный план до дискретного.

\item Провести идентификационный эксперимент согласно полученному дискретному
	оптимальному плану.

\item Сравнить точность оценивания параметров по исходному и оптимальному
	планам.

\end{enumerate}

\section{Теоретический материал}

\subsection{Основы активной параметрической идентификации}

Предоположим, что экспериментатор может произвести $\nu$ повторных запусков
системы, причем сигнал $\alpha_1$ он подает на вход системы $k_1$ раз, сигнал
$\alpha_2$ --- $k_2$ раза и так далее, наконец, сигнал $\alpha_q$ --- $k_q$
раз. В этом случае дискретный (точный) нормированный план эксперимента
$\xi_{\nu}$ представляет собой совокупность точек $\alpha_1, \alpha_2, \ldots,
\alpha_q$, называемых спектром плана, и соответствующих им долей повторных
запусков:
\begin{equation*}
	\xi_{\nu} = \left\{
		\begin{array}{cc} 
			\alpha_1, \alpha_2, \ldots, \alpha_q \\
			\frac{k_1}{\nu}, \frac{k_2}{\nu}, \ldots, \frac{k_q}{\nu}
		\end{array} \right\},\ \alpha_i \in \Omega_{\alpha},\ i = 1, 2, \ldots, q.
\end{equation*}

Каждая точка $\alpha_i$ спектра плана представляет собой последовательность
импульсов, <<развернутую во времени>>, т.е.
\[
	\alpha_i^T = U_i^T = \left\{ [u^i(t_0)]^T, [u^i(t_1)]^T, \ldots,
	[u^i(t_{N-1})]^T \right\},\ i = 1, 2, \ldots, q.
\]
Множество планирования $\Omega_{\alpha}$ определяется ограничениями на условия
проведения эксперимента.

Под непрерывным планом $\xi$ понимается совокупность величин
\begin{equation*}
	\xi = \left\{
		\begin{array}{cc} 
			\alpha_1, \alpha_2, \ldots, \alpha_q \\
			p_1, p_2, \ldots, p_q	
		\end{array} \right\},\ 
	p_i \ge 0,\ \sum\limits_{i=1}^q p_i = 1,\ \alpha_i \in \Omega_{\alpha},\ i = 1, 2, \ldots, q.
\end{equation*}

В отличие от дискретного нормированного плана в непрерывном нормированном плане
снимается условие рациональности весов $p_i$.

Из непрерывного плана можно получить дискретный путем его округления.

Если $L(Y_1^N; \Theta)$ --- плотность совместного распределения вероятностей по
совокупности измерений $Y_1^N = \{ y(t_1), y(t_2), \ldots, y(t_N) \}$ при
фиксированном значении вектора параметров $\Theta$, то информационная матрица
Фишера одноточечного плана определяется выражениями \cite{mono}:
\begin{equation*}
	M(\alpha) = 
	\begin{Vmatrix} 
		\underset{Y}{E}
		\left[ 
			\frac{\partial \ln L(Y_1^N; \Theta)}{\partial \theta_i}
			\frac{\partial \ln L(Y_1^N; \Theta)}{\partial \theta_j}
		\right]
	\end{Vmatrix} =
	\begin{Vmatrix} 
		\underset{Y}{E}
		\left[ 
			-\frac{\partial^2 \ln L(Y_1^N; \Theta)}
			{\partial \theta_i \partial \theta_j}
		\right]
	\end{Vmatrix}
\end{equation*}

Тогда нормированная информационная матрица $M(\xi)$ плана $\xi$ определяется
соотношением:
\[
	M(\xi) = \sum\limits_{i=1}^q p_i M(\alpha_i),
\]
где $M(\alpha_i)$ --- информационные матрицы точек спектра плана.

Задача построения оптимального плана эксперимента $\xi^*$ сводится к задаче:
\[
	\xi^* = \arg \min\limits_{\xi \in \Omega_{\xi}} X[M(\xi)],
\]
где $\Omega_{\xi}$ --- область планирования, $X$ --- критерий оптимальности.
Данную задачу можно решать путем прямой и двойственной процедур.

Если через $Y_{i,j}$ обозначить $j$-ю реализацию выходного сигнала ($j = 1, 2,
\ldots, k_i$), соответствующему $i$-му входному сигналу $U_i$ ($i = 1, 2,
\ldots, q$), то в результате проведения по плану $\xi_{\nu}$ идентификационных
экспериментов будет сформировано множество
\[
	\Xi = \left\{ 
		(U_i, Y_{i,j}),\ j = 1, 2, \ldots, k_i,\ i = 1, 2, \ldots, q
	\right\}
\]

Уточним структуру $Y_{i,j}$:
\[
	Y_{i,j}	= \left\{ 
		[y^{i,j}(t_1)]^T, [y^{i,j}(t_2)]^T, \ldots, [y^{i,j}(t_N)]^T \right\},\
		j = 1, 2, \ldots, k_i,\ i = 1, 2, \ldots, q
\]

Задача оценивания параметров $\theta$ сводится к задаче:
\[
	\hat{\theta} = \arg \min\limits_{\theta \in \Omega_{\theta}} \chi(\Xi,
	\theta),
\]
где $\chi$ --- критерий идентификации.

\subsubsection{Алгоритм процедуры активной параметрической идентификации:}

\begin{enumerate}
	\item взять произвольный (можно случайный) план $\xi_0$,
		тогда в результате проведения идентификационных экспериментов по данному
		плану будет сформировано множество $\Xi_0$,
	\item получить начальные оценки $\hat{\theta}_0$ параметров модели
		по плану $\xi_0$, решая задачу:
\[
	\hat{\theta}_0 = \arg\min\limits_{\theta \in \Omega_{\theta}}
		\chi(\Xi_0, \theta),
\]
	\item провести процедуру (прямую или двойственную) оптимального планирования
		входных сигналов --- получить план $\xi^{*}$, решая следующую задачу,
		используя найденные найденные ранее оценки $\hat{\theta}_0$:
\[
	\xi^{*} = \arg\min\limits_{\xi \in \Omega_{\xi}} X[M(\xi), \hat{\theta}_0].
\]
	Множество, сформированное в результате проведения идентификационных
		экспериментов по плану $\xi^{*}$ обозначим как $\Xi^{*}$.
	\item получить конечные оценки $\hat{\theta}$ параметров модели по ранее
		синтезированному оптимальному плану $\xi^{*}$:
\[
	\hat{\theta} = \arg\min\limits_{\theta \in \Omega_{\theta}} \chi(\Xi^{*},
		\theta),
\]
и закончить процесс.

\end{enumerate}

\newpage
\subsection{Описание модельной структуры}

Модель стохастической динамической линейной дискретной системы в пространстве
состояний в виде \cite{mono}:
\begin{equation}
  \label{eq:initmod}
  \left\{ 
    \begin{array}{lll}
      \vec{x}(t_{k+1}) &= F \vec{x}(t_k) + C \vec{u}(t_k) + G \vec{w}(t_k),&\\
      \vec{y}(t_{k+1}) &= H \vec{x}(t_{k+1}) + \vec{v}(t_{k+1}), 
      & k = 0,\ldots, N-1
    \end{array} 
  \right. 
\end{equation}

Здесь:
\begin{description}
  \item [$\vec{x}(t_k)$] -- $n$-вектор состояния;
  \item [$F$] -- матрица перехода состояния;
  \item [$\vec{u}(t_k)$] -- $r$-вектор управления (входного воздействия);
  \item [$C$] -- матрица управления;
  \item [$\vec{w}(t_k)$] -- $p$-вектор возмущений;
  \item [$G$] -- матрица влияния возмущений;
  \item [$H$] -- матрица наблюдения;
  \item [$\vec{v}(t_{k+1})$] -- $m$-вектор шума измерений;
  \item [$\vec{y}(t_{k+1})$] -- $m$-вектор наблюдений (измерений) отклика;
\end{description}

$F, C, G, H$ --- матрицы соответствующих размеров.

\bigskip
Априорные предположения:
\begin{itemize}
\item $F$ устойчива;
\item пары $(F, C)$ и $(F, G)$ управляемы;
\item пара $(F, H)$ --- наблюдаема;
\item $\vec{w}(t_k)$ и $\vec{v}(t_{k+1})$ --- случайные векторы, образующие
стационарные белые гауссовские последовательности, причем:
\[
E[\vec{w}(t_k)] = 0,\ E[\vec{w}(t_k)\vec{w}^{T}(t_l)] = Q \delta_{k,l}\ ;
\]
\[
E[\vec{v}(t_{k+0}) = 0,\ E[\vec{v}(t_{k+1})\vec{v}^{T}(t_{l+1})] = R
\delta_{k,l}\;
\]
\[
E[\vec{v}(t_k)\vec{w}^{T}(t_k)] = 0,
\]
для любых $k, l = 0, 1, \ldots, N-1$ ($\delta_{k,l}$ --- символ Кронекера);

\item начальное состояние $\vec{x}(0)$ имеет нормальное распределение с
параметрами $\overline{\vec{x}}(0)$ и $P(0)$ и не коррелирует с $\vec{w(t_k)}$
и $\vec{v_{k+1}}$ при любых значениях $k$.

Будем считать, что подлежащие оцениванию параметры $\theta = (\theta_1,
\theta_2, \ldots, \theta_s)$ могут входить в элементы матриц $F, C, G, H, Q, R,
P(0)$ и в вектор $\overline{\vec{x}}(0)$ в различных комбинациях.

\end{itemize}

\subsection{Критерий идентификации}

В качестве критерия идентификации используется логарифмическая функция
правдоподобия. Для одноточечного плана эксперимента она имеет вид \cite{mono}:
\begin{equation*}
\begin{split}
	\chi(\theta, U_i, Y_{i,j}) = -\ln{L(\theta)} = \frac{Nm}{2}\ ln{2\pi} + \frac{1}{2}
  \sum\limits_{k=0}^{N-1} \left[ \eps^T(t_{k+1}) B^{-1}(t_{k+1}) \eps(t_{k+1}) \right]
  + \\ + \frac{1}{2} \sum\limits_{k=0}^{N-1} \ln \det B^{-1}(t_{k+1}).
\end{split}
\end{equation*}

Критерий идентификации для многоточечного плана имеет вид:

\begin{equation*}
	\chi(\Xi, \theta) =
		\sum\limits_{i=1}^{q} \sum\limits_{j=1}^{k_i} \chi(\theta, U_i, Y_{i,j})
\end{equation*}

\subsection{Градиент критерия идентификации}

Выражение для градиента критерия для одноточечного плана имеет вид \cite{mono}:
\begin{equation*}
\begin{split}
  \frac{\partial \chi(\theta)}{\partial \theta_i} = \sum\limits_{k=0}^{N-1}
  \left[ \frac{\partial \eps(t_{k+1})}{\partial \theta_i} \right]^T
  B^{-1}(t_{k+1}) \left[ \eps(t_{k+1}) \right] - \\
  - \frac{1}{2}
  \sum\limits_{k=0}^{N-1} \left[ \eps(t_{k+1}) \right]^T B^{-1}(t_{k+1})
  \frac{\partial B(t_{k+1})}{\partial \theta_i} B^{-1}(t_{k+1}) \eps(t_{k+1}) +
  \\ + 
  \frac{1}{2} \sum\limits_{k=0}^{N-1} \Sp \left[ B^{-1}(t_{k+1})
  \frac{\partial B(t_{k+1})}{\partial \theta_i} \right]. 
\end{split}
\end{equation*}

Выражение градиента критерия для многоточечного плана можно легко получить по
правилу дифференцирования суммы.

% imports
\begin{pythontexcustomcode}{py}
import numpy as np
import dill as pkl
from model.model import Model
import pylatex

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm

def surf_plot_save(X, Y, Z, filepath):
    fig = plt.figure()
    ax = fig.gca(projection='3d')

    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,
                           linewidth=0, antialiased=False)

    ax.set_xlabel(r'$\theta_1$')
    ax.set_ylabel(r'$\theta_2$')
    ax.set_zlabel(r'$L(\theta_1, \theta_2)$')

    ax.zaxis.get_major_formatter().set_powerlimits((0, 1))

    plt.savefig(filepath, bbox_inches='tight')
\end{pythontexcustomcode}

\section{Примеры решений}

% define, create model 1
\begin{pycode}[model1]
F = lambda th: [[th[0], 0.],
                [0., th[1]]]

C = lambda th: [[1.0, 0.],
                [0., 1.0]]

G = lambda th: [[1.0, 0.],
                [0., 1.0]]

H = lambda th: [[1.0, 0.],
                [0., 1.0]]

x0_m = lambda th: [[0.],
                   [0.]]

x0_c = lambda th: [[0.1, 0.],
                   [0., 0.1]]

w_c = lambda th: [[0.05, 0.],
                  [0., 0.05]]

v_c = lambda th: [[0.15, 0.],
                  [0., 0.15]]

th_true = [0.5, 0.5]

# TODO: check if there are extra components in 'th'
m = Model(F, C, G, H, x0_m, x0_c, w_c, v_c, th_true)
\end{pycode}

% TODO: introduce counter
% TODO: print numpy arrays instead of matrices
\subsection{Пример 1}
\[
  \begin{pmatrix} x_1(\fut) \\ x_2(\fut) \end{pmatrix} =
  \begin{pmatrix} \theta_1 & 1 \\ 0 & 0.5 \end{pmatrix}
  \begin{pmatrix} x_1(t_k) \\ x_2(t_k) \end{pmatrix}
  + 
	\begin{pmatrix} \theta_2 \\ 1 \end{pmatrix}
	u(t_k) 
  + \begin{pmatrix} w_1(t_k) \\ w_2(t_k) \end{pmatrix}
\]
\[
  y(\fut) =
	\begin{pmatrix} 1 & 0 \end{pmatrix}
	\begin{pmatrix} x_1(\fut) \\ x_2(\fut) \end{pmatrix} +
  \begin{pmatrix} v_1(\fut) \\ v_2(\fut) \end{pmatrix}
\]
\[
  \overline{x}(0) = \begin{pmatrix} 0 \\ 0 \end{pmatrix},\
  P(0) = \begin{pmatrix} 0.1 & 0 \\ 0 & 0.1 \end{pmatrix},\
  Q = \begin{pmatrix} 0.1 & 0 \\ 0 & 0.1 \end{pmatrix},\
  R = 0.1 
\]

Истинные значения параметров
$\theta_{true} = \begin{pmatrix} 0.5 & 0.5 \end{pmatrix}$ \\

\newpage
\subsubsection{Оценивание параметров по произвольному начальному плану}

\begin{pycode}
import sys
\end{pycode}

Число точек в плане $q = 4$.

Длина точки плана $N = 20$.

Область планирования: $u(t_k) \in [ -1,\ 1 ],\ k = 0, 1, \ldots, N$.

Область оценивания: $ 0.25 \le \theta_i \le 0.75,\ i = 1, 2 $.

Общее число запусков $\nu = 10$. \\

Полученные оценки параметров:
$\hat{\theta} = \begin{bmatrix} 0.342 & 0.559 \end{bmatrix}$.

\newcommand{\rtol}[2]{\frac{||\hat{#1}#2 -
{\hat{#1}#2_{true}}||}{||\hat{#1}#2_{true}||}}

Относительная погрешность в пространстве параметров:
\[
	\delta_{\theta} = \rtol{\theta}{} = 23.9\%.
\]

Средняя относительная погрешность в пространстве откликов:
\[
	\overline{\delta}_Y = \frac{1}{\nu}
		\sum\limits_{i=1}^{q}\sum\limits_{j=1}^{k_i} \rtol{Y}{^{i,j}} = 11.8 \%.
\]

\subsubsection{Синтез оптимального плана и оценивание параметров по плану}

По проведению двойственной процедуры планирования входных сигналов был получен
некоторый оптимальный план. В результате проведения идентификационных экспериментов по
данному плану были получены оценки параметров.

Полученные оценки параметров:
$\hat{\theta} = \begin{bmatrix} 0.46 & 0.47 \end{bmatrix}$.

Относительная погрешность в пространстве параметров:
\[
	\delta_{\theta} = \rtol{\theta}{} = 6.7\%.
\]

Средняя относительная погрешность в пространстве откликов:
\[
	\overline{\delta}_Y = \frac{1}{\nu}
		\sum\limits_{i=1}^{q}\sum\limits_{j=1}^{k_i} \rtol{Y}{^{i,j}} = 2.6 \%.
\]

\section{Выводы}

По результатам эксперимента видно уменьшение погрешности оценок при оценивании
по оптимальному плану. Таким образом подтверждается эффективность процедуры
активной параметрической идентификации.

\begin{thebibliography}{9}

\begin{sloppypar}

\bibitem{mono} Активная параметрическая идентификация стохастических линейных
  систем: монография / В.И. Денисов, В.М. Чубич, О.С. Черникова, Д.И. Бобылева.
    --- Новосибирск : Изд-во НГТУ, 2009. --- 192 с.
    (Серия <<Монографии НГТУ>>).

\end{sloppypar}

\end{thebibliography}

\renewcommand{\baselinestretch}{1}

\begin{appendices}

\section{Исходные тексты программ}

% TODO: make pycode, within it print pyverbatim, read source file and print it
\begin{pyverbatim}[][fontsize=\small]

import math
import tensorflow as tf
import control
import numpy as np
from tensorflow.contrib.distributions import MultivariateNormalFullCovariance
import scipy


class Model(object):

    # TODO: introduce some more default argument values, check types, cast if
    # neccessary
    def __init__(self, F, C, G, H, x0_mean, x0_cov, w_cov, v_cov, th):
        """
        Arguments are all callables (functions) of 'th' returning python lists
        except for 'th' itself (of course)
        """

        # TODO: evaluate and cast everything to numpy matrices first
        # TODO: cast floats, ints to numpy matrices
        # TODO: allow both constant matrices and callables

        # store arguments, after that check them
        self.__F = F
        self.__C = C
        self.__G = G
        self.__H = H
        self.__x0_mean = x0_mean
        self.__x0_cov = x0_cov
        self.__w_cov = w_cov
        self.__v_cov = v_cov
        self.__th = th

        # evaluate all functions
        th = np.array(th)
        F = np.array(F(th))
        C = np.array(C(th))
        H = np.array(H(th))
        G = np.array(G(th))
        w_cov = np.array(w_cov(th))    # Q
        v_cov = np.array(v_cov(th))    # R
        x0_m = np.array(x0_mean(th))
        x0_cov = np.array(x0_cov(th))  # P_0

        # get dimensions and store them as well
        self.__n = n = F.shape[0]
        self.__m = m = H.shape[0]
        self.__p = p = G.shape[1]
        self.__r = r = C.shape[1]

        # generate means
        w_mean = np.zeros([p, 1], np.float64)
        v_mean = np.zeros([m, 1], np.float64)

        # and store them
        self.__w_mean = w_mean
        self.__v_mean = v_mean

        # check conformability
        u = np.ones([r, 1])
        # generate random vectors
        # squeeze, because mean must be one dimensional
        x = np.random.multivariate_normal(x0_m.squeeze(), x0_cov)
        w = np.random.multivariate_normal(w_mean.squeeze(), w_cov)
        v = np.random.multivariate_normal(v_mean.squeeze(), v_cov)

        # shape them as column-vectors
        x = x.reshape([n, 1])
        w = w.reshape([p, 1])
        v = v.reshape([m, 1])

        # if model is not conformable, exception would be raised (thrown) here
        F * x + C * u + G * w
        H * x + v

        # check controllability, stability, observability
        self.__validate()

        # if the execution reached here, all is fine so
        # define corresponding computational tensorflow graphs
        self.__define_observations_simulation()
        self.__define_likelihood_computation()

    def __define_observations_simulation(self):
        # TODO: reduce code not to create extra operations

        self.__sim_graph = tf.Graph()
        sim_graph = self.__sim_graph

        r = self.__r
        m = self.__m
        n = self.__n
        p = self.__p

        x0_mean = self.__x0_mean
        x0_cov = self.__x0_cov

        with sim_graph.as_default():

            th = tf.placeholder(tf.float64, shape=[None], name='th')

            # TODO: this should be continuous function of time
            # but try to let pass array also
            u = tf.placeholder(tf.float64, shape=[r, None], name='u')

            t = tf.placeholder(tf.float64, shape=[None], name='t')

            # TODO: refactor

            # FIXME: gradient of py_func is None
            # TODO: embed function itself in the graph, must rebuild the graph
            # if the structure of the model change
            # use tf.convert_to_tensor
            F = tf.convert_to_tensor(self.__F(th), tf.float64)
            F.set_shape([n, n])

            C = tf.convert_to_tensor(self.__C(th), tf.float64)
            C.set_shape([n, r])

            G = tf.convert_to_tensor(self.__G(th), tf.float64)
            G.set_shape([n, p])

            H = tf.convert_to_tensor(self.__H(th), tf.float64)
            H.set_shape([m, n])

            x0_mean = tf.convert_to_tensor(x0_mean(th), tf.float64)
            x0_mean = tf.squeeze(x0_mean)

            x0_cov = tf.convert_to_tensor(x0_cov(th), tf.float64)
            x0_cov.set_shape([n, n])

            x0_dist = MultivariateNormalFullCovariance(x0_mean, x0_cov,
                                                       name='x0_dist')

            Q = tf.convert_to_tensor(self.__w_cov(th), tf.float64)
            Q.set_shape([p, p])

            w_mean = self.__w_mean.squeeze()
            w_dist = MultivariateNormalFullCovariance(w_mean, Q, name='w_dist')

            R = tf.convert_to_tensor(self.__v_cov(th), tf.float64)
            R.set_shape([m, m])
            v_mean = self.__v_mean.squeeze()
            v_dist = MultivariateNormalFullCovariance(v_mean, R, name='v_dist')

            def sim_obs(x):
                v = v_dist.sample()
                v = tf.reshape(v, [m, 1])
                y = H @ x + v  # the syntax is valid for Python >= 3.5
                return y

            def sim_loop_cond(x, y, t, k):
                N = tf.stack([tf.shape(t)[0]])
                N = tf.reshape(N, ())
                return tf.less(k, N-1)

            def sim_loop_body(x, y, t, k):

                # TODO: this should be function of time
                u_t_k = tf.slice(u, [0, k], [r, 1])

                def state_propagate(x):
                    w = w_dist.sample()
                    w = tf.reshape(w, [p, 1])
                    Fx = tf.matmul(F, x, name='Fx')
                    Cu = tf.matmul(C, u_t_k, name='Cu')
                    Gw = tf.matmul(G, w, name='Gw')
                    x = Fx + Cu + Gw
                    return x

                tk = tf.slice(t, [k], [2], 'tk')

                x_k = x[:, -1]
                x_k = tf.reshape(x_k, [n, 1])

                x_k = state_propagate(x_k)

                y_k = sim_obs(x_k)

                # TODO: stack instead of concat
                x = tf.concat([x, x_k], 1)
                y = tf.concat([y, y_k], 1)

                k = k + 1

                return x, y, t, k

            x = x0_dist.sample(name='x0_sample')
            x = tf.reshape(x, [n, 1], name='x')

            # this zeroth measurement should be thrown away
            y = sim_obs(x)
            k = tf.constant(0, name='k')

            shape_invariants = [tf.TensorShape([n, None]),
                                tf.TensorShape([m, None]),
                                t.get_shape(),
                                k.get_shape()]

            sim_loop = tf.while_loop(sim_loop_cond, sim_loop_body,
                                     [x, y, t, k], shape_invariants,
                                     name='sim_loop')

            self.__sim_loop_op = sim_loop

    # defines graph
    def __define_likelihood_computation(self):

        self.__lik_graph = tf.Graph()
        lik_graph = self.__lik_graph

        r = self.__r
        m = self.__m
        n = self.__n
        p = self.__p

        x0_mean = self.__x0_mean
        x0_cov = self.__x0_cov

        with lik_graph.as_default():
            # FIXME: Don't Repeat Yourself (in simulation and here)
            th = tf.placeholder(tf.float64, shape=[None], name='th')
            u = tf.placeholder(tf.float64, shape=[r, None], name='u')
            t = tf.placeholder(tf.float64, shape=[None], name='t')
            y = tf.placeholder(tf.float64, shape=[m, None], name='y')

            N = tf.stack([tf.shape(t)[0]])
            N = tf.reshape(N, ())

            F = tf.convert_to_tensor(self.__F(th), tf.float64)
            F.set_shape([n, n])

            C = tf.convert_to_tensor(self.__C(th), tf.float64)
            C.set_shape([n, r])

            G = tf.convert_to_tensor(self.__G(th), tf.float64)
            G.set_shape([n, p])

            H = tf.convert_to_tensor(self.__H(th), tf.float64)
            H.set_shape([m, n])

            x0_mean = tf.convert_to_tensor(x0_mean(th), tf.float64)
            x0_mean.set_shape([n, 1])

            P_0 = tf.convert_to_tensor(x0_cov(th), tf.float64)
            P_0.set_shape([n, n])

            Q = tf.convert_to_tensor(self.__w_cov(th), tf.float64)
            Q.set_shape([p, p])

            R = tf.convert_to_tensor(self.__v_cov(th), tf.float64)
            R.set_shape([m, m])

            I = tf.eye(n, n, dtype=tf.float64)

            def lik_loop_cond(k, P, S, t, u, x, y):
                return tf.less(k, N-1)

            def lik_loop_body(k, P, S, t, u, x, y):

                # TODO: this should be function of time
                u_t_k = tf.slice(u, [0, k], [r, 1])

                # k+1, cause zeroth measurement should not be taken into account
                y_k = tf.slice(y, [0, k+1], [m, 1])

                t_k = tf.slice(t, [k], [2], 't_k')

                # TODO: extract Kalman filter to a separate class
                def state_predict(x):
                    Fx = tf.matmul(F, x, name='Fx')
                    Cu = tf.matmul(C, u_t_k, name='Cu')
                    x = Fx + Cu
                    return x

                def covariance_predict(P):
                    GQtG = tf.matmul(G @ Q, G, transpose_b=True)
                    PtF = tf.matmul(P, F, transpose_b=True)
                    P = tf.matmul(F, P) + PtF + GQtG
                    return P

                x = state_predict(x)

                P = covariance_predict(P)

                E = y_k - tf.matmul(H, x)

                B = tf.matmul(H @ P, H, transpose_b=True) + R
                invB = tf.matrix_inverse(B)

                K = tf.matmul(P, H, transpose_b=True) @ invB

                S_k = tf.matmul(E, invB @ E, transpose_a=True)
                S_k = 0.5 * (S_k + tf.log(tf.matrix_determinant(B)))

                S = S + S_k

                # state update
                x = x + tf.matmul(K, E)

                # covariance update
                P = (I - K @ H) @ P

                k = k + 1

                return k, P, S, t, u, x, y

            k = tf.constant(0, name='k')
            P = P_0
            S = tf.constant(0.0, dtype=tf.float64, shape=[1, 1], name='S')
            x = x0_mean

            # TODO: make a named tuple of named list
            lik_loop = tf.while_loop(lik_loop_cond, lik_loop_body,
                                     [k, P, S, t, u, x, y], name='lik_loop')

            dS = tf.gradients(lik_loop[2], th)

            self.__lik_loop_op = lik_loop
            self.__dS = dS

    def __isObservable(self, th=None):
        if th is None:
            th = self.__th
        F = np.array(self.__F(th))
        C = np.array(self.__C(th))
        n = self.__n
        obsv_matrix = control.obsv(F, C)
        rank = np.linalg.matrix_rank(obsv_matrix)
        return rank == n

    def __isControllable(self, th=None):
        if th is None:
            th = self.__th
        F = np.array(self.__F(th))
        C = np.array(self.__C(th))
        n = self.__n
        ctrb_matrix = control.ctrb(F, C)
        rank = np.linalg.matrix_rank(ctrb_matrix)
        return rank == n

    # FIXME: fix to discrete
    def __isStable(self, th=None):
        if th is None:
            th = self.__th
        F = np.array(self.__F(th))
        eigv = np.linalg.eigvals(F)
        real_parts = np.real(eigv)
        return np.all(real_parts < 0)

    def __validate(self, th=None):
        # FIXME: do not raise exceptions
        # TODO: prove, print matrices and their criteria
        if not self.__isControllable(th):
            # raise Exception('''Model is not controllable. Set different
            #                structure or parameters values''')
            pass

        if not self.__isStable(th):
            # raise Exception('''Model is not stable. Set different structure or
            #                parameters values''')
            pass

        if not self.__isObservable(th):
            # raise Exception('''Model is not observable. Set different
            #                structure or parameters values''')
            pass

    def sim(self, u, th=None):
        if th is None:
            th = self.__th

        k = u.shape[1]
        t = np.linspace(0, k-1, k)

        self.__validate(th)
        g = self.__sim_graph

        if t.shape[0] != u.shape[1]:
            raise Exception('''t.shape[0] != u.shape[1]''')

        # run simulation graph
        with tf.Session(graph=g) as sess:
            t_ph = g.get_tensor_by_name('t:0')
            th_ph = g.get_tensor_by_name('th:0')
            u_ph = g.get_tensor_by_name('u:0')
            rez = sess.run(self.__sim_loop_op, {th_ph: th, t_ph: t, u_ph: u})

        return rez

    def lik(self, u, y, th=None):

        # hack continuous to discrete system
        k = u.shape[1]
        t = np.linspace(0, k-1, k)

        if th is None:
            th = self.__th

        # to numpy 1D array
        th = np.array(th).squeeze()

        # self.__validate(th)
        g = self.__lik_graph

        # TODO: check for y also
        if t.shape[0] != u.shape[1]:
            raise Exception('''t.shape[0] != u.shape[1]''')

        # run lik graph
        with tf.Session(graph=g) as sess:
            t_ph = g.get_tensor_by_name('t:0')
            th_ph = g.get_tensor_by_name('th:0')
            u_ph = g.get_tensor_by_name('u:0')
            y_ph = g.get_tensor_by_name('y:0')
            rez = sess.run(self.__lik_loop_op, {th_ph: th, t_ph: t, u_ph: u,
                                                y_ph: y})

        # FIXME: fix to discrete
        N = len(t)
        m = y.shape[0]
        S = rez[2]
        S = S + N*m * 0.5 + np.log(2*math.pi)

        return S

    def __L(self, th, u, y):
        return self.lik(u, y, th)

    def __dL(self, th, u, y):
        return self.dL(u, y, th)

    def dL(self, u, y, th=None):
        if th is None:
            th = self.__th

        # hack continuous to discrete system
        k = u.shape[1]
        t = np.linspace(0, k-1, k)

        # to 1D numpy array
        th = np.array(th).squeeze()

        # self.__validate(th)
        g = self.__lik_graph

        if t.shape[0] != u.shape[1]:
            raise Exception('''t.shape[0] != u.shape[1]''')

        # run lik graph
        with tf.Session(graph=g) as sess:
            t_ph = g.get_tensor_by_name('t:0')
            th_ph = g.get_tensor_by_name('th:0')
            u_ph = g.get_tensor_by_name('u:0')
            y_ph = g.get_tensor_by_name('y:0')
            rez = sess.run(self.__dS, {th_ph: th, t_ph: t, u_ph: u, y_ph: y})

        return rez[0]

    def mle_fit(self, th, u, y):
        # TODO: call slsqp
        th0 = th
        th = scipy.optimize.minimize(self.__L, th0, args=(u, y),
                                     jac=self.__dL, options={'disp': True})
        return th
\end{pyverbatim}

\end{appendices}

\end{document}

# vim: ts=2 sw=2
